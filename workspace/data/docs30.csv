docid|title|abstract|url|authors
0|Bayesian Models and Decision Algorithms for Complex Early Phase Clinical Trials|An early phase clinical trial is the first step in evaluating the effects in humans of a potential new anti-disease agent or combination of agents. Usually called "phase I" or "phase I/II" trials, these experiments typically have the nominal scientific goal of determining an acceptable dose, most often based on adverse event probabilities. This arose from a tradition of phase I trials to evaluate cytotoxic agents for treating cancer, although some methods may be applied in other medical settings, such as treatment of stroke or immunological diseases. Most modern statistical designs for early phase trials include model-based, outcome-adaptive decision rules that choose doses for successive patient cohorts based on data from previous patients in the trial. Such designs have seen limited use in clinical practice, however, due to their complexity, the requirement of intensive, computer-based data monitoring, and the medical community's resistance to change. Still, many actual applications of model-based outcome-adaptive designs have been remarkably successful in terms of both patient benefit and scientific outcome. In this paper I will review several Bayesian early phase trial designs that were tailored to accommodate specific complexities of the treatment regime and patient outcomes in particular clinical settings.|http://arxiv.org/abs/1011.6494v1|Peter F. Thall
1|Deep Historical Borrowing Framework to Prospectively and Simultaneously Synthesize Control Information in Confirmatory Clinical Trials with Multiple Endpoints|In current clinical trial development, historical information is receiving more attention as it provides utility beyond sample size calculation. Meta-analytic-predictive (MAP) priors and robust MAP priors have been proposed for prospectively borrowing historical data on a single endpoint. To simultaneously synthesize control information from multiple endpoints in confirmatory clinical trials, we propose to approximate posterior probabilities from a Bayesian hierarchical model and estimate critical values by deep learning to construct pre-specified strategies for hypothesis testing. This feature is important to ensure study integrity by establishing prospective decision functions before the trial conduct. Simulations are performed to show that our method properly controls family-wise error rate (FWER) and preserves power as compared with a typical practice of choosing constant critical values given a subset of null space. Satisfactory performance under prior-data conflict is also demonstrated. We further illustrate our method using a case study in Immunology.|http://arxiv.org/abs/2008.12774v2|Tianyu Zhan,Yiwang Zhou,Ziqian Geng,Yihua Gu,Jian Kang,Li Wang,Xiaohong Huang,Elizabeth H. Slate
2|Parametric Resonance May Explain Virologic Failure to HIV Treatment Interruptions|Pilot studies of structured treatment interruptions (STI) in HIV therapy have shown that patients can maintain low viral loads whilst benefiting from reduced treatment toxicity. However, a recent STI clinical trial reported a high degree of virologic failure. Here we present a novel hypothesis that could explain virologic failure to STI and provides new insights of great clinical relevance. We analyze a classic mathematical model of HIV within-host viral dynamics and find that nonlinear parametric resonance occurs when STI are added to the model; resonance is observed as virologic failure. We use the model to simulate clinical trial data and to calculate patient-specific resonant spectra. We gain two important insights. Firstly, within an STI trial, we determine that patients who begin with similar viral loads can be expected to show extremely different virologic responses as a result of resonance. Thus, high heterogeneity of patient response within a STI clinical trial is to be expected. Secondly and more importantly, we determine that virologic failure is not simply due to STI or patient characteristics; rather it is the result of a complex dynamic interaction between STI and patient viral dynamics. Hence, our analyses demonstrate that no universal regimen with periodic interruptions will be effective for all patients. On the basis of our results, we suggest that immunologic and virologic parameters should be used to design patient-specific STI regimens.|http://arxiv.org/abs/q-bio/0504031v1|Romulus Breban,Sally Blower
3|Efficient nonparametric inference on the effects of stochastic interventions under two-phase sampling, with applications to vaccine efficacy trials|The advent and subsequent widespread availability of preventive vaccines has altered the course of public health over the past century. Despite this success, effective vaccines to prevent many high-burden diseases, including HIV, have been slow to develop. Vaccine development can be aided by the identification of immune response markers that serve as effective surrogates for clinically significant infection or disease endpoints. However, measuring immune response marker activity is often costly, which has motivated the usage of two-phase sampling for immune response evaluation in clinical trials of preventive vaccines. In such trials, the measurement of immunological markers is performed on a subset of trial participants, where enrollment in this second phase is potentially contingent on the observed study outcome and other participant-level information. We propose nonparametric methodology for efficiently estimating a counterfactual parameter that quantifies the impact of a given immune response marker on the subsequent probability of infection. Along the way, we fill in theoretical gaps pertaining to the asymptotic behavior of nonparametric efficient estimators in the context of two-phase sampling, including a multiple robustness property enjoyed by our estimators. Techniques for constructing confidence intervals and hypothesis tests are presented, and an open source software implementation of the methodology, the txshift R package, is introduced. We illustrate the proposed techniques using data from a recent preventive HIV vaccine efficacy trial.|http://arxiv.org/abs/2003.13771v2|Nima S. Hejazi,Mark J. van der Laan,Holly E. Janes,Peter B. Gilbert,David C. Benkeser
4|DEMO: Dose Exploration, Monitoring, and Optimization Using a Biological Mediator for Clinical Outcomes|Phase 1-2 designs provide a methodological advance over phase 1 designs for dose finding by using both clinical response and toxicity. A phase 1-2 trial still may fail to select a truly optimal dose. because early response is not a perfect surrogate for long term therapeutic success. To address this problem, a generalized phase 1-2 design first uses a phase 1-2 design's components to identify a set of candidate doses, adaptively randomizes patients among the candidates, and after longer follow up selects a dose to maximize long-term success rate. In this paper, we extend this paradigm by proposing a design that exploits an early treatment-related, real-valued biological outcome, such as pharmacodynamic activity or an immunological effect, that may act as a mediator between dose and clinical outcomes, including tumor response, toxicity, and survival time. We assume multivariate dose-outcome models that include effects appearing in causal pathways from dose to the clinical outcomes. Bayesian model selection is used to identify and eliminate biologically inactive doses. At the end of the trial, a therapeutically optimal dose is chosen from the set of doses that are acceptably safe, clinically effective, and biologically active to maximize restricted mean survival time. Results of a simulation study show that the proposed design may provide substantial improvements over designs that ignore the biological variable.|http://arxiv.org/abs/2404.02120v1|Cheng-Han Yang,Peter F. Thall,Ruitao Lin
5|Estimating treatment effects with competing intercurrent events in randomized controlled trials|The analysis of randomized controlled trials is often complicated by intercurrent events--events that occur after treatment initiation and may impact outcome assessment. These events may lead to patients discontinuing their assigned treatment or dropping out of the trial entirely. In an analysis of data from two recent immunology trials, we categorize intercurrent events into two broad types: those unrelated to treatment (e.g., withdrawal from the study due to external factors like pandemics or relocation) and those related to treatment (e.g., adverse events or lack of efficacy). We adopt distinct strategies to handle each type, aiming to target a clinically more relevant estimand. For treatment-related intercurrent events, they often meaningfully describe the patient's outcome, we employ a composite variable strategy, where we attribute an outcome value that reflects the lack of treatment success. For treatment-unrelated intercurrent events, we adopt a hypothetical strategy that assumes these event times are conditionally independent of the outcome, given treatment and covariates, and envisions a scenario in which the intercurrent events do not occur. We establish the nonparametric identification and semiparametric estimation theory for the causal estimand and introduce doubly robust estimators. We illustrate our methods through the re-analysis of two randomized trials on baricitinib for Systemic Lupus Erythematosus. We classify intercurrent events, apply four estimators, and compare our approach with common ad-hoc methods, highlighting the robustness and practical implications of our framework.|http://arxiv.org/abs/2503.03049v1|Sizhu Lu,Yanyao Yi,Yongming Qu,Huayu Karen Liu,Ting Ye,Peng Ding
6|Unlocking Historical Clinical Trial Data with ALIGN: A Compositional Large Language Model System for Medical Coding|The reuse of historical clinical trial data has significant potential to accelerate medical research and drug development. However, interoperability challenges, particularly with missing medical codes, hinders effective data integration across studies. While Large Language Models (LLMs) offer a promising solution for automated coding without labeled data, current approaches face challenges on complex coding tasks. We introduce ALIGN, a novel compositional LLM-based system for automated, zero-shot medical coding. ALIGN follows a three-step process: (1) diverse candidate code generation; (2) self-evaluation of codes and (3) confidence scoring and uncertainty estimation enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing medication terms into Anatomical Therapeutic Chemical (ATC) and medical history terms into Medical Dictionary for Regulatory Activities (MedDRA) codes extracted from 22 immunology trials. ALIGN outperformed the LLM baselines, while also providing capabilities for trustworthy deployment. For MedDRA coding, ALIGN achieved high accuracy across all levels, matching RAG and excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN demonstrated superior performance, particularly at lower hierarchy levels (ATC Level 4), with 72-73% overall accuracy and 86-89% accuracy for common medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably enhancing performance on uncommon medications. ALIGN achieves this cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o, reducing barriers to clinical adoption. ALIGN advances automated medical coding for clinical trial data, contributing to enhanced data interoperability and reusability, positioning it as a promising tool to improve clinical research and accelerate drug development.|http://arxiv.org/abs/2411.13163v1|Nabeel Seedat,Caterina Tozzi,Andrea Hita Ardiaca,Mihaela van der Schaar,James Weatherall,Adam Taylor
7|An immunological autobiography: my year as a COVID-19 vaccine trial participant|I present here longitudinal evaluation of T and B cell immunity to SARS-CoV2 and variants of concern (VOC) from a single subject (me) over an entire year post vaccination. After enrolling in the Moderna phase III clinical trial, I collected my own biological samples pre- and post-immunization in the event of being a recipient of the experimental vaccine. The evidence strongly supports the conclusion that I did not receive the placebo. The analysis is admittedly limited to an n of 1, but the results fit well with data taken from published works and represent one of the more comprehensive longitudinal evaluations of vaccine-elicited immunity within a single individual yet to be undertaken. Though the data amount to a well-documented anecdote, given its granularity, it is not without its insights and may be of further use in directing future longitudinal studies that have actual statistical significance.|http://arxiv.org/abs/2111.01282v2|Ross M. Kedl
8|What Radio Waves Tell Us about Sleep|The ability to assess sleep at home, capture sleep stages, and detect the occurrence of apnea (without on-body sensors) simply by analyzing the radio waves bouncing off people's bodies while they sleep is quite powerful. Such a capability would allow for longitudinal data collection in patients' homes, informing our understanding of sleep and its interaction with various diseases and their therapeutic responses, both in clinical trials and routine care. In this article, we develop an advanced machine learning algorithm for passively monitoring sleep and nocturnal breathing from radio waves reflected off people while asleep. Validation results in comparison with the gold standard (i.e., polysomnography) (n=849) demonstrate that the model captures the sleep hypnogram (with an accuracy of 81% for 30-second epochs categorized into Wake, Light Sleep, Deep Sleep, or REM), detects sleep apnea (AUROC = 0.88), and measures the patient's Apnea-Hypopnea Index (ICC=0.95; 95% CI = [0.93, 0.97]). Notably, the model exhibits equitable performance across race, sex, and age. Moreover, the model uncovers informative interactions between sleep stages and a range of diseases including neurological, psychiatric, cardiovascular, and immunological disorders. These findings not only hold promise for clinical practice and interventional trials but also underscore the significance of sleep as a fundamental component in understanding and managing various diseases.|http://arxiv.org/abs/2405.11739v2|Hao He,Chao Li,Wolfgang Ganglberger,Kaileigh Gallagher,Rumen Hristov,Michail Ouroutzoglou,Haoqi Sun,Jimeng Sun,Brandon Westover,Dina Katabi
9|Distinguishing immunological and behavioral effects of vaccination|The interpretation of vaccine efficacy estimands is subtle, even in randomized trials designed to quantify immunological effects of vaccination. In this article, we introduce terminology to distinguish between different vaccine efficacy estimands and clarify their interpretations. This allows us to explicitly consider immunological and behavioural effects of vaccination, and establish that policy-relevant estimands can differ substantially from those commonly reported in vaccine trials. We further show that a conventional vaccine trial allows identification and estimation of different vaccine estimands under plausible conditions, if one additional post-treatment variable is measured. Specifically, we utilize a ``belief variable'' that indicates the treatment an individual believed they had received. The belief variable is similar to ``blinding assessment'' variables that are occasionally collected in placebo-controlled trials in other fields. We illustrate the relations between the different estimands, and their practical relevance, in numerical examples based on an influenza vaccine trial.|http://arxiv.org/abs/2311.08335v1|Mats Stensrud,Daniel Nevo,Uri Obolski
10|Panacea: A foundation model for clinical trial search, summarization, design, and recruitment|Clinical trials are fundamental in developing new drugs, medical devices, and treatments. However, they are often time-consuming and have low success rates. Although there have been initial attempts to create large language models (LLMs) for clinical trial design and patient-trial matching, these models remain task-specific and not adaptable to diverse clinical trial tasks. To address this challenge, we propose a clinical trial foundation model named Panacea, designed to handle multiple tasks, including trial search, trial summarization, trial design, and patient-trial matching. We also assemble a large-scale dataset, named TrialAlign, of 793,279 trial documents and 1,113,207 trial-related scientific papers, to infuse clinical knowledge into the model by pre-training. We further curate TrialInstruct, which has 200,866 of instruction data for fine-tuning. These resources enable Panacea to be widely applicable for a range of clinical trial tasks based on user requirements.   We evaluated Panacea on a new benchmark, named TrialPanorama, which covers eight clinical trial tasks. Our method performed the best on seven of the eight tasks compared to six cutting-edge generic or medicine-specific LLMs. Specifically, Panacea showed great potential to collaborate with human experts in crafting the design of eligibility criteria, study arms, and outcome measures, in multi-round conversations. In addition, Panacea achieved 14.42% improvement in patient-trial matching, 41.78% to 52.02% improvement in trial search, and consistently ranked at the top for five aspects of trial summarization. Our approach demonstrates the effectiveness of Panacea in clinical trials and establishes a comprehensive resource, including training data, model, and benchmark, for developing clinical trial foundation models, paving the path for AI-based clinical trial development.|http://arxiv.org/abs/2407.11007v1|Jiacheng Lin,Hanwen Xu,Zifeng Wang,Sheng Wang,Jimeng Sun
11|Assessment of Immune Correlates of Protection via Controlled Vaccine Efficacy and Controlled Risk|Immune correlates of protection (CoPs) are immunologic biomarkers accepted as a surrogate for an infectious disease clinical endpoint and thus can be used for traditional or provisional vaccine approval. To study CoPs in randomized, placebo-controlled trials, correlates of risk (CoRs) are first assessed in vaccine recipients. This analysis does not assess causation, as a CoR may fail to be a CoP. We propose a causal CoP analysis that estimates the controlled vaccine efficacy curve across biomarker levels $s$, $CVE(s)$, equal to one minus the ratio of the controlled-risk curve $r_C(s)$ at $s$ and placebo risk, where $r_C(s)$ is causal risk if all participants are assigned vaccine and the biomarker is set to $s$. The criterion for a useful CoP is wide variability of $CVE(s)$ in $s$. Moreover, estimation of $r_C(s)$ is of interest in itself, especially in studies without a placebo arm. For estimation of $r_C(s)$, measured confounders can be adjusted for by any regression method that accommodates missing biomarkers, to which we add sensitivity analysis to quantify robustness of CoP evidence to unmeasured confounding. Application to two harmonized phase 3 trials supports that 50% neutralizing antibody titer has value as a controlled vaccine efficacy CoP for virologically confirmed dengue (VCD): in CYD14 the point estimate (95% confidence interval) for $CVE(s)$ accounting for measured confounders and building in conservative margin for unmeasured confounding increases from 29.6% (95% CI 3.5 to 45.9) at titer 1:36 to 78.5% (95% CI 67.9 to 86.8) at titer 1:1200; these estimates are 17.4% (95% CI -14.4 to 36.5) and 84.5% (95% CI 79.6 to 89.1) for CYD15.|http://arxiv.org/abs/2107.05734v1|Peter B. Gilbert,Youyi Fong,Marco Carone
12|Rank-Based Identification of High-dimensional Surrogate Markers: Application to Vaccinology|In vaccine trials with long-term participant follow-up, it is of great importance to identify surrogate markers that accurately infer long-term immune responses. These markers offer practical advantages such as providing early, indirect evidence of vaccine efficacy, and can accelerate vaccine development while identifying potential biomarkers. High-throughput technologies like RNA-sequencing have emerged as promising tools for understanding complex biological systems and informing new treatment strategies. However, these data are high-dimensional, presenting unique statistical challenges for existing surrogate marker identification methods. We introduce Rank-based Identification of high-dimensional SurrogatE Markers (RISE), a novel approach designed for small sample, high-dimensional settings typical in modern vaccine experiments. RISE employs a non-parametric univariate test to screen variables for promising candidates, followed by surrogate evaluation on independent data. Our simulation studies demonstrate RISE's desirable properties, including type one error rate control and empirical power under various conditions. Applying RISE to a clinical trial for inactivated influenza vaccination, we sought to identify genes whose post-vaccination expression could serve as a surrogate for the induced immune response. This analysis revealed a signature of genes whose combined expression at 1 day post-injection appears to be a reasonable surrogate for the neutralising antibody titres at 28 days after vaccination. Pathways related to innate antiviral signalling and interferon stimulation were strongly represented in this derived surrogate, providing a clear immunological interpretation.|http://arxiv.org/abs/2502.03030v1|Arthur Hughes,Layla Parast,Rodolphe Thiébaut,Boris P. Hejblum
13|Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using Self-Supervision|Clinical trials are essential for drug development but are extremely expensive and time-consuming to conduct. It is beneficial to study similar historical trials when designing a clinical trial. However, lengthy trial documents and lack of labeled data make trial similarity search difficult. We propose a zero-shot clinical trial retrieval method, Trial2Vec, which learns through self-supervision without annotating similar clinical trials. Specifically, the meta-structure of trial documents (e.g., title, eligibility criteria, target disease) along with clinical knowledge (e.g., UMLS knowledge base https://www.nlm.nih.gov/research/umls/index.html) are leveraged to automatically generate contrastive samples. Besides, Trial2Vec encodes trial documents considering meta-structure thus producing compact embeddings aggregating multi-aspect information from the whole document. We show that our method yields medically interpretable embeddings by visualization and it gets a 15% average improvement over the best baselines on precision/recall for trial retrieval, which is evaluated on our labeled 1600 trial pairs. In addition, we prove the pre-trained embeddings benefit the downstream trial outcome prediction task over 240k trials. Software ias available at https://github.com/RyanWangZf/Trial2Vec.|http://arxiv.org/abs/2206.14719v2|Zifeng Wang,Jimeng Sun
14|SPOT: Sequential Predictive Modeling of Clinical Trial Outcome with Meta-Learning|Clinical trials are essential to drug development but time-consuming, costly, and prone to failure. Accurate trial outcome prediction based on historical trial data promises better trial investment decisions and more trial success. Existing trial outcome prediction models were not designed to model the relations among similar trials, capture the progression of features and designs of similar trials, or address the skewness of trial data which causes inferior performance for less common trials.   To fill the gap and provide accurate trial outcome prediction, we propose Sequential Predictive mOdeling of clinical Trial outcome (SPOT) that first identifies trial topics to cluster the multi-sourced trial data into relevant trial topics. It then generates trial embeddings and organizes them by topic and time to create clinical trial sequences. With the consideration of each trial sequence as a task, it uses a meta-learning strategy to achieve a point where the model can rapidly adapt to new tasks with minimal updates. In particular, the topic discovery module enables a deeper understanding of the underlying structure of the data, while sequential learning captures the evolution of trial designs and outcomes. This results in predictions that are not only more accurate but also more interpretable, taking into account the temporal patterns and unique characteristics of each trial topic. We demonstrate that SPOT wins over the prior methods by a significant margin on trial outcome benchmark data: with a 21.5\% lift on phase I, an 8.9\% lift on phase II, and a 5.5\% lift on phase III trials in the metric of the area under precision-recall curve (PR-AUC).|http://arxiv.org/abs/2304.05352v1|Zifeng Wang,Cao Xiao,Jimeng Sun
15|Smooth and probabilistic PARAFAC model with auxiliary covariates|In immunological and clinical studies, matrix-valued time-series data clustering is increasingly popular. Researchers are interested in finding low-dimensional embedding of subjects based on potentially high-dimensional longitudinal features and investigating relationships between static clinical covariates and the embedding. These studies are often challenging due to high dimensionality, as well as the sparse and irregular nature of sample collection along the time dimension. We propose a smoothed probabilistic PARAFAC model with covariates (SPACO) to tackle these two problems while utilizing auxiliary covariates of interest. We provide intensive simulations to test different aspects of SPACO and demonstrate its use on an immunological data set from patients with SARs-CoV-2 infection.|http://arxiv.org/abs/2104.05184v3|Leying Guan
16|Optimal Allocation of Gold Standard Testing under Constrained Availability: Application to Assessment of HIV Treatment Failure|The World Health Organization (WHO) guidelines for monitoring the effectiveness of HIV treatment in resource-limited settings (RLS) are mostly based on clinical and immunological markers (e.g., CD4 cell counts). Recent research indicates that the guidelines are inadequate and can result in high error rates. Viral load (VL) is considered the "gold standard", yet its widespread use is limited by cost and infrastructure. In this paper, we propose a diagnostic algorithm that uses information from routinely-collected clinical and immunological markers to guide a selective use of VL testing for diagnosing HIV treatment failure, under the assumption that VL testing is available only at a certain portion of patient visits. Our algorithm identifies the patient subpopulation, such that the use of limited VL testing on them minimizes a pre-defined risk (e.g., misdiagnosis error rate). Diagnostic properties of our proposal algorithm are assessed by simulations. For illustration, data from the Miriam Hospital Immunology Clinic (RI, USA) are analyzed.|http://arxiv.org/abs/2010.00692v1|Tao Liu,Joseph W. Hogan,Lisa Wang,Shangxuan Zhang,Rami Kantor
17|Exploring the Generalization of Cancer Clinical Trial Eligibility Classifiers Across Diseases|Clinical trials are pivotal in medical research, and NLP can enhance their success, with application in recruitment. This study aims to evaluate the generalizability of eligibility classification across a broad spectrum of clinical trials. Starting with phase 3 cancer trials, annotated with seven eligibility exclusions, then to determine how well models can generalize to non-cancer and non-phase 3 trials. To assess this, we have compiled eligibility criteria data for five types of trials: (1) additional phase 3 cancer trials, (2) phase 1 and 2 cancer trials, (3) heart disease trials, (4) type 2 diabetes trials, and (5) observational trials for any disease, comprising 2,490 annotated eligibility criteria across seven exclusion types. Our results show that models trained on the extensive cancer dataset can effectively handle criteria commonly found in non-cancer trials, such as autoimmune diseases. However, they struggle with criteria disproportionately prevalent in cancer trials, like prior malignancy. We also experiment with few-shot learning, demonstrating that a limited number of disease-specific examples can partially overcome this performance gap. We are releasing this new dataset of annotated eligibility statements to promote the development of cross-disease generalization in clinical trial classification.|http://arxiv.org/abs/2403.17135v1|Yumeng Yang,Ashley Gilliam,Ethan B Ludmir,Kirk Roberts
18|TrialSynth: Generation of Synthetic Sequential Clinical Trial Data|Analyzing data from past clinical trials is part of the ongoing effort to optimize the design, implementation, and execution of new clinical trials and more efficiently bring life-saving interventions to market. While there have been recent advances in the generation of static context synthetic clinical trial data, due to both limited patient availability and constraints imposed by patient privacy needs, the generation of fine-grained synthetic time-sequential clinical trial data has been challenging. Given that patient trajectories over an entire clinical trial are of high importance for optimizing trial design and efforts to prevent harmful adverse events, there is a significant need for the generation of high-fidelity time-sequence clinical trial data. Here we introduce TrialSynth, a Variational Autoencoder (VAE) designed to address the specific challenges of generating synthetic time-sequence clinical trial data. Distinct from related clinical data VAE methods, the core of our method leverages Hawkes Processes (HP), which are particularly well-suited for modeling event-type and time gap prediction needed to capture the structure of sequential clinical trial data. Our experiments demonstrate that TrialSynth surpasses the performance of other comparable methods that can generate sequential clinical trial data at varying levels of fidelity / privacy tradeoff, enabling the generation of highly accurate event sequences across multiple real-world sequential event datasets with small patient source populations. Notably, our empirical findings highlight that TrialSynth not only outperforms existing clinical sequence-generating methods but also produces data with superior utility while empirically preserving patient privacy.|http://arxiv.org/abs/2409.07089v2|Chufan Gao,Mandis Beigi,Afrah Shafquat,Jacob Aptekar,Jimeng Sun
19|Clinical Trial Information Extraction with BERT|Natural language processing (NLP) of clinical trial documents can be useful in new trial design. Here we identify entity types relevant to clinical trial design and propose a framework called CT-BERT for information extraction from clinical trial text. We trained named entity recognition (NER) models to extract eligibility criteria entities by fine-tuning a set of pre-trained BERT models. We then compared the performance of CT-BERT with recent baseline methods including attention-based BiLSTM and Criteria2Query. The results demonstrate the superiority of CT-BERT in clinical trial NLP.|http://arxiv.org/abs/2110.10027v1|Xiong Liu,Greg L. Hersch,Iya Khalil,Murthy Devarakonda
20|CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models|New medical treatment development requires multiple phases of clinical trials. Despite the significant human and financial costs of bringing a drug to market, less than 20% of drugs in testing will make it from the first phase to final approval. Recent literature indicates that the design of the trial protocols significantly contributes to trial performance. We investigated Clinical Trial Outcome Prediction (CTOP) using trial design documents to predict phase transitions automatically. We propose CTP-LLM, the first Large Language Model (LLM) based model for CTOP. We also introduce the PhaseTransition (PT) Dataset; which labels trials based on their progression through the regulatory process and serves as a benchmark for CTOP evaluation. Our fine-tuned GPT-3.5-based model (CTP-LLM) predicts clinical trial phase transition by analyzing the trial's original protocol texts without requiring human-selected features. CTP-LLM achieves a 67% accuracy rate in predicting trial phase transitions across all phases and a 75% accuracy rate specifically in predicting the transition from Phase~III to final approval. Our experimental performance highlights the potential of LLM-powered applications in forecasting clinical trial outcomes and assessing trial design.|http://arxiv.org/abs/2408.10995v1|Michael Reinisch,Jianfeng He,Chenxi Liao,Sauleh Ahmad Siddiqui,Bei Xiao
21|Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development|Background The cost of drug discovery and development is substantial, with clinical trial outcomes playing a critical role in regulatory approval and patient care. However, access to large-scale, high-quality clinical trial outcome data remains limited, hindering advancements in predictive modeling and evidence-based decision-making.   Methods We present the Clinical Trial Outcome (CTO) benchmark, a fully reproducible, large-scale repository encompassing approximately 125,000 drug and biologics trials. CTO integrates large language model (LLM) interpretations of publications, trial phase progression tracking, sentiment analysis from news sources, stock price movements of trial sponsors, and additional trial-related metrics. Furthermore, we manually annotated a dataset of clinical trials conducted between 2020 and 2024 to enhance the quality and reliability of outcome labels.   Results The trial outcome labels in the CTO benchmark agree strongly with expert annotations, achieving an F1 score of 94 for Phase 3 trials and 91 across all phases. Additionally, benchmarking standard machine learning models on our manually annotated dataset revealed distribution shifts in recent trials, underscoring the necessity of continuously updated labeling approaches.   Conclusions By analyzing CTO's performance on recent clinical trials, we demonstrate the ongoing need for high-quality, up-to-date trial outcome labels. We publicly release the CTO knowledge base and annotated labels at https://chufangao.github.io/CTOD, with regular updates to support research on clinical trial outcomes and inform data-driven improvements in drug development.|http://arxiv.org/abs/2406.10292v3|Chufan Gao,Jathurshan Pradeepkumar,Trisha Das,Shivashankar Thati,Jimeng Sun
22|Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation|Machine learning (ML) exhibits promise in the clinical domain. However, it is constrained by data scarcity and ethical considerations, as the generation of clinical trials presents significant challenges due to stringent privacy regulations, high costs, and the extended duration required for conducting studies with human participants. Despite the advancements of large language models (LLMs) in general generation tasks, their potential in facilitating the generation of synthetic clinical trials is under-explored. To address this gap, we introduce a novel Retrieval-Reasoning few-shot framework that leverages LLMs to generate artificial yet realistic and diverse clinical trials with binary success/failure labels. Experiments conducted on real clinical trials from the \url{ClinicalTrials.gov} database demonstrate that our synthetic data can effectively augment real datasets. Furthermore, by fine-tuning a pre-trained model as a binary classifier on synthetic clinical trial datasets, we demonstrate that this augmentation enhances model training for downstream tasks such as trial outcome prediction. Our findings suggest that LLMs for synthetic clinical trial generation hold promise for accelerating clinical research and upholding ethical standards for patient privacy. The code is publicly available at https://anonymous.4open.science/r/Retrieval_Reasoning_Clinical_Trial_Generation-3EC4.|http://arxiv.org/abs/2410.12476v2|Zerui Xu,Fang Wu,Yuanyuan Zhang,Yue Zhao
23|From Bench to Bedside: A Review of Clinical Trials in Drug Discovery and Development|Clinical trials are an indispensable part of the drug development process, bridging the gap between basic research and clinical application. During the development of new drugs, clinical trials are used not only to evaluate the safety and efficacy of the drug but also to explore its dosage, treatment regimens, and potential side effects. This review discusses the various stages of clinical trials, including Phase I (safety assessment), Phase II (preliminary efficacy evaluation), Phase III (large-scale validation), and Phase IV (post-marketing surveillance), highlighting the characteristics of each phase and their interrelationships. Additionally, the paper addresses the major challenges encountered in clinical trials, such as ethical issues, subject recruitment difficulties, diversity and representativeness concerns, and proposes strategies for overcoming these challenges. With the advancement of technology, innovative technologies such as artificial intelligence, big data, and digitalization are gradually transforming clinical trial design and implementation, improving trial efficiency and data quality. The article also looks forward to the future of clinical trials, particularly the impact of emerging therapies such as gene therapy and immunotherapy on trial design, as well as the importance of regulatory reforms and global collaboration. In conclusion, the core role of clinical trials in drug development will continue to drive the progress of innovative drug development and clinical treatment.|http://arxiv.org/abs/2412.09378v2|Tianyang Wang,Ming Liu,Benji Peng,Xinyuan Song,Charles Zhang,Xintian Sun,Qian Niu,Junyu Liu,Silin Chen,Keyu Chen,Ming Li,Pohsun Feng,Ziqian Bi,Yunze Wang,Yichao Zhang,Cheng Fei,Lawrence KQ Yan
24|Estimating Design Operating Characteristics in Bayesian Adaptive Clinical Trials|Bayesian adaptive designs have gained popularity in all phases of clinical trials with numerous new developments in the past few decades. During the COVID-19 pandemic, the need to establish evidence for the effectiveness of vaccines, therapeutic treatments and policies that could resolve or control the crisis emphasized the advantages offered by efficient and flexible clinical trial designs. In many COVID-19 clinical trials, due to the high level of uncertainty, Bayesian adaptive designs were considered advantageous. Designing Bayesian adaptive trials, however, requires extensive simulation studies that are generally considered challenging, particularly in time-sensitive settings such as a pandemic. In this article, we propose a set of methods for efficient estimation and uncertainty quantification for design operating characteristics of Bayesian adaptive trials. Specifically, we model the sampling distribution of Bayesian probability statements that are commonly used as the basis of decision making. To showcase the implementation and performance of the proposed approach, we use a clinical trial design with an ordinal disease-progression scale endpoint that was popular among COVID-19 trial. However, the proposed methodology may be applied generally in clinical trial context where design operating characteristics cannot be obtained analytically.|http://arxiv.org/abs/2105.03022v2|Shirin Golchi
25|Artificial Intelligence for In Silico Clinical Trials: A Review|A clinical trial is an essential step in drug development, which is often costly and time-consuming. In silico trials are clinical trials conducted digitally through simulation and modeling as an alternative to traditional clinical trials. AI-enabled in silico trials can increase the case group size by creating virtual cohorts as controls. In addition, it also enables automation and optimization of trial design and predicts the trial success rate. This article systematically reviews papers under three main topics: clinical simulation, individualized predictive modeling, and computer-aided trial design. We focus on how machine learning (ML) may be applied in these applications. In particular, we present the machine learning problem formulation and available data sources for each task. We end with discussing the challenges and opportunities of AI for in silico trials in real-world applications.|http://arxiv.org/abs/2209.09023v1|Zifeng Wang,Chufan Gao,Lucas M. Glass,Jimeng Sun
26|Language Interaction Network for Clinical Trial Approval Estimation|Clinical trial outcome prediction seeks to estimate the likelihood that a clinical trial will successfully reach its intended endpoint. This process predominantly involves the development of machine learning models that utilize a variety of data sources such as descriptions of the clinical trials, characteristics of the drug molecules, and specific disease conditions being targeted. Accurate predictions of trial outcomes are crucial for optimizing trial planning and prioritizing investments in a drug portfolio. While previous research has largely concentrated on small-molecule drugs, there is a growing need to focus on biologics-a rapidly expanding category of therapeutic agents that often lack the well-defined molecular properties associated with traditional drugs. Additionally, applying conventional methods like graph neural networks to biologics data proves challenging due to their complex nature. To address these challenges, we introduce the Language Interaction Network (LINT), a novel approach that predicts trial outcomes using only the free-text descriptions of the trials. We have rigorously tested the effectiveness of LINT across three phases of clinical trials, where it achieved ROC-AUC scores of 0.770, 0.740, and 0.748 for phases I, II, and III, respectively, specifically concerning trials involving biologic interventions.|http://arxiv.org/abs/2405.06662v1|Chufan Gao,Tianfan Fu,Jimeng Sun
27|Speed and accuracy in a visual motion discrimination task as performed by rats|We find that rats, like primates and humans, perform better on the random dot motion task when they take more time to respond. We provide evidence that this improvement is due to stimulus integration. Rats increase their response latency modestly as a function of trial difficulty. Rats can modulate response latency more strongly on a trial by trial basis, apparently on the basis of reward-related parameters.|http://arxiv.org/abs/1206.0311v1|Pamela Reinagel,Emily Mankin,Adam Calhoun
28|A Latent Gaussian Process Model with Application to Monitoring Clinical Trials|In many clinical trials treatments need to be repeatedly applied as diseases relapse frequently after remission over a long period of time (e.g., 35 weeks). Most research in statistics focuses on the overall trial design, such as sample size and power calculation, or on the data analysis after trials are completed. Little is done to improve the efficiency of trial monitoring, such as early termination of trials due to futility. The challenge faced in such trial monitoring is mostly caused by the need to properly model repeated outcomes from patients. We propose a Bayesian trial monitoring scheme for clinical trials with repeated and potentially cyclic binary outcomes. We construct a latent Gaussian process (LGP) to model discrete longitudinal data in those trials. LGP describes the underlying latent process that gives rise to the observed longitudinal binary outcomes. The posterior consistency property of the proposed model is studied. Posterior inference is conducted with a hybrid Monte Carlo algorithm. Simulation studies are conducted under various clinical scenarios, and a case study is reported based on a real-life trial.|http://arxiv.org/abs/1403.7853v1|Yanxun Xu,Yuan Ji
29|Clinical trial site matching with improved diversity using fair policy learning|The ongoing pandemic has highlighted the importance of reliable and efficient clinical trials in healthcare. Trial sites, where the trials are conducted, are chosen mainly based on feasibility in terms of medical expertise and access to a large group of patients. More recently, the issue of diversity and inclusion in clinical trials is gaining importance. Different patient groups may experience the effects of a medical drug/ treatment differently and hence need to be included in the clinical trials. These groups could be based on ethnicity, co-morbidities, age, or economic factors. Thus, designing a method for trial site selection that accounts for both feasibility and diversity is a crucial and urgent goal. In this paper, we formulate this problem as a ranking problem with fairness constraints. Using principles of fairness in machine learning, we learn a model that maps a clinical trial description to a ranked list of potential trial sites. Unlike existing fairness frameworks, the group membership of each trial site is non-binary: each trial site may have access to patients from multiple groups. We propose fairness criteria based on demographic parity to address such a multi-group membership scenario. We test our method on 480 real-world clinical trials and show that our model results in a list of potential trial sites that provides access to a diverse set of patients while also ensuing a high number of enrolled patients.|http://arxiv.org/abs/2204.06501v1|Rakshith S Srinivasa,Cheng Qian,Brandon Theodorou,Jeffrey Spaeder,Cao Xiao,Lucas Glass,Jimeng Sun
